{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCvqFUknUUEgGyZNTfZgUv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e86a4d9c7acb4a0f8ec85deba988f9c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_681efb7a01f744889afdeb11a3acf08c",
              "IPY_MODEL_a36be79510f5469fa411ca82d09c9480",
              "IPY_MODEL_35f512a1297d4451b03ed91c6f3c0980"
            ],
            "layout": "IPY_MODEL_03f5c3b7f06443d5beae94faeb243dbe"
          }
        },
        "681efb7a01f744889afdeb11a3acf08c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_570a1f1350914957af50e70638e3474d",
            "placeholder": "​",
            "style": "IPY_MODEL_31dd3cc63a8c495a906b2a8f7a900e47",
            "value": "README.md: 100%"
          }
        },
        "a36be79510f5469fa411ca82d09c9480": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f63940fce735425a8032c8a5d3b8e557",
            "max": 10663,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62dc4ec1238e40eabfb49941b2d870cd",
            "value": 10663
          }
        },
        "35f512a1297d4451b03ed91c6f3c0980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a70b5c7358a74b9d85a4ee630a11b4eb",
            "placeholder": "​",
            "style": "IPY_MODEL_730179dc42404d0795504d87fd4ec58f",
            "value": " 10.7k/10.7k [00:00&lt;00:00, 165kB/s]"
          }
        },
        "03f5c3b7f06443d5beae94faeb243dbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "570a1f1350914957af50e70638e3474d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31dd3cc63a8c495a906b2a8f7a900e47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f63940fce735425a8032c8a5d3b8e557": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62dc4ec1238e40eabfb49941b2d870cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a70b5c7358a74b9d85a4ee630a11b4eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "730179dc42404d0795504d87fd4ec58f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec88b3ad563e4e48b7629ea8790b5ed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05969d0b5288420f994c994e3230d869",
              "IPY_MODEL_ec5bcc0c9c1e46de808f14cc0650d161",
              "IPY_MODEL_417228c5333147ef882d71185566ec7b"
            ],
            "layout": "IPY_MODEL_3d0c2b8145194ac689f9a9e4983332a7"
          }
        },
        "05969d0b5288420f994c994e3230d869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83ec8282c1d54a84b0bfe9ba7edebf46",
            "placeholder": "​",
            "style": "IPY_MODEL_6c5e4b0886084d6cabc56676c20ccb38",
            "value": "voxpopuli.py: 100%"
          }
        },
        "ec5bcc0c9c1e46de808f14cc0650d161": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4c6f9d253c74f09adfb2bea910ce81d",
            "max": 8839,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9eb1af0792434fa49019e2b5874a20b3",
            "value": 8839
          }
        },
        "417228c5333147ef882d71185566ec7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7cb57823c954af48d8c4a2354e06ad0",
            "placeholder": "​",
            "style": "IPY_MODEL_4eb4221a72bc414f994f3cf26b4ff655",
            "value": " 8.84k/8.84k [00:00&lt;00:00, 158kB/s]"
          }
        },
        "3d0c2b8145194ac689f9a9e4983332a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83ec8282c1d54a84b0bfe9ba7edebf46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c5e4b0886084d6cabc56676c20ccb38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4c6f9d253c74f09adfb2bea910ce81d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9eb1af0792434fa49019e2b5874a20b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d7cb57823c954af48d8c4a2354e06ad0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4eb4221a72bc414f994f3cf26b4ff655": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mayibongwemoyo/dawm/blob/main/new_pfb_new_detector_gm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import sys\n",
        "!pip install torchaudio==0.13.1\n",
        "!pip install soundfile datasets librosa pandas seaborn matplotlib scipy sklearn\n",
        "!pip install datasets\n",
        "!pip install audioseal\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/dawn/examples')\n",
        "# from datasets import load_dataset\n",
        "import torch\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy import signal\n",
        "# import urllib.request\n",
        "import urllib\n",
        "import io\n",
        "from audioseal import AudioSeal"
      ],
      "metadata": {
        "id": "BqFLXdluI28D"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "S9IBFAk7_JOt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "561d1838-70db-49c1-d582-50e145157f07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AudioSeal models loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "# import sys\n",
        "# import torch\n",
        "# import torchaudio\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from audioseal import AudioSeal\n",
        "# from scipy import stats # Keep for potential future statistical tests\n",
        "\n",
        "# Constants from your code\n",
        "NUM_WATERMARKS = 4\n",
        "SAMPLE_RATE = 16000\n",
        "sr = 16000 # Alias for convenience\n",
        "\n",
        "# Initialize models (assuming these are loaded correctly)\n",
        "# Ensure you have the correct model paths/names if not using default download\n",
        "try:\n",
        "    generator = AudioSeal.load_generator(\"audioseal_wm_16bits\")\n",
        "    detector = AudioSeal.load_detector(\"audioseal_detector_16bits\")\n",
        "    print(\"AudioSeal models loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading AudioSeal models: {e}\")\n",
        "    # Handle error appropriately, maybe stop execution or use placeholder models\n",
        "\n",
        "def preprocess_audio(audio, sr):\n",
        "    \"\"\"Convert audio to standard format: (1, 1, T) @ 16kHz\"\"\"\n",
        "    # Convert numpy arrays to tensor\n",
        "    if isinstance(audio, np.ndarray):\n",
        "        audio = torch.from_numpy(audio).float()\n",
        "\n",
        "    # Ensure 3D shape: (batch=1, channels=1, time)\n",
        "    if audio.dim() == 1:\n",
        "        audio = audio.unsqueeze(0).unsqueeze(0)  # (1, 1, T)\n",
        "    elif audio.dim() == 2:\n",
        "        # Assuming (C, T), add batch dimension\n",
        "        if audio.shape[0] > 1 and audio.shape[1] > 1: # Check if likely (C, T)\n",
        "             audio = audio.unsqueeze(0) # (1, C, T)\n",
        "        else: # Likely (T, C) or similar, needs reshape/check\n",
        "            print(f\"Warning: Unexpected 2D audio shape {audio.shape}. Assuming (T, C) and taking first channel.\")\n",
        "            audio = audio[:, 0].unsqueeze(0).unsqueeze(0) # Take first channel -> (1, 1, T)\n",
        "\n",
        "    # Convert to mono if needed\n",
        "    if audio.shape[1] > 1:\n",
        "        audio = audio.mean(dim=1, keepdim=True)\n",
        "\n",
        "    # Resample to 16kHz\n",
        "    if sr != SAMPLE_RATE:\n",
        "        resampler = torchaudio.transforms.Resample(sr, SAMPLE_RATE)\n",
        "        audio = resampler(audio)\n",
        "\n",
        "    # Ensure float32 type\n",
        "    audio = audio.float()\n",
        "\n",
        "    # Normalize audio amplitude to prevent clipping issues during watermarking\n",
        "    # This is a common practice but might need adjustment based on AudioSeal's specifics\n",
        "    max_val = torch.max(torch.abs(audio))\n",
        "    if max_val > 1.0:\n",
        "        print(f\"Warning: Audio amplitude max {max_val} > 1.0. Normalizing.\")\n",
        "        audio = audio / max_val\n",
        "    elif max_val == 0:\n",
        "        print(\"Warning: Audio signal is silent.\")\n",
        "        return audio # Avoid division by zero\n",
        "\n",
        "    return audio\n",
        "\n",
        "def calculate_snr(original, watermarked):\n",
        "    \"\"\"Calculates Signal-to-Noise Ratio in dB.\"\"\"\n",
        "    noise = watermarked - original\n",
        "    # Add epsilon to prevent log10(0) or division by zero\n",
        "    epsilon = 1e-10\n",
        "    signal_power = torch.mean(original.pow(2))\n",
        "    noise_power = torch.mean(noise.pow(2))\n",
        "\n",
        "    if noise_power < epsilon:\n",
        "        print(\"Warning: Noise power is near zero. Setting SNR to infinity (e.g., 100 dB).\")\n",
        "        return 100.0 # Assign a high value for near-zero noise\n",
        "\n",
        "    if signal_power < epsilon:\n",
        "         print(\"Warning: Signal power is near zero. SNR might be misleading or infinite.\")\n",
        "         if noise_power < epsilon:\n",
        "              return 0.0 # Or handle as undefined; signal and noise are both zero\n",
        "         else:\n",
        "              # Signal is zero, noise is not; SNR is effectively -infinity\n",
        "              return -100.0 # Assign a very low value\n",
        "\n",
        "    snr = 10 * torch.log10(signal_power / (noise_power + epsilon))\n",
        "    return snr.item()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_pfb(audio, sr, step, alpha=0.5, num_bands=4):\n",
        "    \"\"\"Apply one watermark step (Parallel Frequency Bands - step-wise).\"\"\"\n",
        "    if not isinstance(audio, torch.Tensor):\n",
        "        raise TypeError(\"Input audio must be a PyTorch tensor.\")\n",
        "    if audio.dim() != 3 or audio.shape[0] != 1 or audio.shape[1] != 1:\n",
        "         raise ValueError(f\"Input audio must have shape (1, 1, T), but got {audio.shape}\")\n",
        "\n",
        "\n",
        "    fft_audio = torch.fft.fft(audio.squeeze(0).squeeze(0)) # Perform FFT on the 1D signal (T,)\n",
        "    bands = torch.chunk(fft_audio, num_bands, dim=-1)\n",
        "\n",
        "    target_band_idx = step % num_bands\n",
        "    band_to_watermark = bands[target_band_idx]\n",
        "\n",
        "    # AudioSeal generator expects shape (B, T) or (B, C, T)\n",
        "    # We need to adapt the 1D frequency band.\n",
        "    # Option 1: Watermark only the real part (as in your original attempt)\n",
        "    # This might discard important phase information.\n",
        "    # watermarked_real = generator(band_to_watermark.real.unsqueeze(0), sample_rate=sr, alpha=alpha)\n",
        "    # watermarked_complex_band = watermarked_real.squeeze(0) + 1j * band_to_watermark.imag\n",
        "\n",
        "    # Option 2: Treat complex numbers carefully. AudioSeal might not directly support complex inputs.\n",
        "    # A common approach is to watermark magnitude or phase separately, or use a complex-aware model if available.\n",
        "    # Let's try watermarking the real part for now, acknowledging its limitation.\n",
        "    # Assuming generator works on (B, T)-like shape:\n",
        "    real_part_unsqueezed = band_to_watermark.real.unsqueeze(0).unsqueeze(0) # Shape (1, 1, T_band)\n",
        "    watermarked_real_part = generator(real_part_unsqueezed, sample_rate=sr, alpha=alpha)\n",
        "    watermarked_complex_band = watermarked_real_part.squeeze(0).squeeze(0) + 1j * band_to_watermark.imag\n",
        "\n",
        "\n",
        "    watermarked_bands = list(bands)\n",
        "    watermarked_bands[target_band_idx] = watermarked_complex_band\n",
        "\n",
        "    # Reconstruct the full spectrum and apply inverse FFT\n",
        "    reconstructed_fft = torch.cat(watermarked_bands, dim=-1)\n",
        "    watermarked_audio_1d = torch.fft.ifft(reconstructed_fft).real\n",
        "\n",
        "    # Reshape back to (1, 1, T)\n",
        "    watermarked_audio = watermarked_audio_1d.unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "    return watermarked_audio"
      ],
      "metadata": {
        "id": "0vVt4bY7_Rg6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_pfb(watermarked_audio, sr, step, message, num_bands=4, detection_threshold=0.5):\n",
        "    \"\"\"\n",
        "    Detect watermark in a specific frequency band (Parallel Frequency Bands).\n",
        "\n",
        "    Args:\n",
        "        watermarked_audio (torch.Tensor): The audio signal possibly containing watermarks (shape 1, 1, T).\n",
        "        sr (int): Sample rate.\n",
        "        step (int): The watermark step (determines which band to check, 0-indexed).\n",
        "        message (torch.Tensor): The secret message bits (shape 1, N_BITS) to test against.\n",
        "                                Usually 16 bits for AudioSeal.\n",
        "        num_bands (int): Number of frequency bands used during embedding.\n",
        "        detection_threshold (float): Confidence threshold for successful detection.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (detection_probability (float), is_detected (bool), detected_bits (torch.Tensor or None))\n",
        "               is_detected is True if prob > threshold.\n",
        "               detected_bits contains the extracted bits if detection is attempted.\n",
        "    \"\"\"\n",
        "    if not isinstance(watermarked_audio, torch.Tensor):\n",
        "        raise TypeError(\"Input audio must be a PyTorch tensor.\")\n",
        "    if watermarked_audio.dim() != 3 or watermarked_audio.shape[0] != 1 or watermarked_audio.shape[1] != 1:\n",
        "         raise ValueError(f\"Input audio must have shape (1, 1, T), but got {watermarked_audio.shape}\")\n",
        "\n",
        "\n",
        "    fft_audio = torch.fft.fft(watermarked_audio.squeeze(0).squeeze(0)) # Perform FFT on the 1D signal (T,)\n",
        "    bands = torch.chunk(fft_audio, num_bands, dim=-1)\n",
        "\n",
        "    target_band_idx = step % num_bands\n",
        "    band_to_check = bands[target_band_idx]\n",
        "\n",
        "    # Prepare the band for the AudioSeal detector\n",
        "    # The detector likely expects a time-domain signal of shape (B, T) or (B, C, T).\n",
        "    # We need to inverse FFT the *specific band* (potentially zero-padded)\n",
        "    # or use a detector modified for frequency domain input if available.\n",
        "\n",
        "    # Approach 1: Inverse FFT the single band (might not be what AudioSeal expects)\n",
        "    # Zero-pad other bands to maintain original length for IFFT\n",
        "    zero_band = torch.zeros_like(band_to_check)\n",
        "    padded_fft = [zero_band] * num_bands\n",
        "    padded_fft[target_band_idx] = band_to_check\n",
        "    reconstructed_fft_single_band = torch.cat(padded_fft, dim=-1)\n",
        "    audio_single_band_1d = torch.fft.ifft(reconstructed_fft_single_band).real\n",
        "\n",
        "    # Reshape for detector\n",
        "    audio_to_detect = audio_single_band_1d.unsqueeze(0).unsqueeze(0) # Shape (1, 1, T)\n",
        "\n",
        "    # --- Detection ---\n",
        "    detector.message = message # Set the message to test for\n",
        "    try:\n",
        "        # Use the standard detector on the isolated band's time-domain representation\n",
        "        # Note: Performance might be suboptimal as the detector wasn't trained for this.\n",
        "        prob, detected_bits = detector.detect_watermark(audio_to_detect, sr)\n",
        "\n",
        "        detection_prob = prob.item() if hasattr(prob, 'item') else float(prob) # Ensure float\n",
        "        is_detected = detection_prob > detection_threshold\n",
        "\n",
        "        # Calculate BER for this specific detection attempt\n",
        "        ber = (message.round() != detected_bits.round()).float().mean().item()\n",
        "\n",
        "        #print(f\"Step {step+1} (Band {target_band_idx+1}): Prob={detection_prob:.2f}, BER={ber:.2f}, Detected={is_detected}\")\n",
        "\n",
        "        return detection_prob, is_detected, detected_bits.round(), ber\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during detection for step {step} (Band {target_band_idx}): {e}\")\n",
        "        return 0.0, False, None, 1.0 # Return failure state"
      ],
      "metadata": {
        "id": "9qxLNovj_XeH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics_pfb(original, watermarked, step, num_fake=10, num_bands=4):\n",
        "    \"\"\"Calculate metrics for a single PFB watermark step.\"\"\"\n",
        "    snr = calculate_snr(original, watermarked)\n",
        "\n",
        "    # Real message detection for the specific band/step\n",
        "    real_msg = torch.randint(0, 2, (1, 16), dtype=torch.float32) # Ensure float32 for BER calc\n",
        "    prob_real, is_detected_real, detected_real, ber_real = detect_pfb(\n",
        "        watermarked, SAMPLE_RATE, step, real_msg, num_bands=num_bands\n",
        "    )\n",
        "\n",
        "    # Fake message detection (False Positives) for the specific band/step\n",
        "    false_positives_count = 0\n",
        "    for _ in range(num_fake):\n",
        "        fake_msg = torch.randint(0, 2, (1, 16), dtype=torch.float32)\n",
        "        # Ensure fake_msg is different from real_msg for a meaningful FP test\n",
        "        while torch.equal(fake_msg, real_msg):\n",
        "             fake_msg = torch.randint(0, 2, (1, 16), dtype=torch.float32)\n",
        "\n",
        "        prob_fake, is_detected_fake, _, _ = detect_pfb(\n",
        "            watermarked, SAMPLE_RATE, step, fake_msg, num_bands=num_bands\n",
        "        )\n",
        "        if is_detected_fake:\n",
        "            false_positives_count += 1\n",
        "\n",
        "    false_positive_rate = false_positives_count / num_fake\n",
        "\n",
        "    return {\n",
        "        \"method\": \"PFB\",\n",
        "        \"step\": step + 1,  # 1-based indexing for reporting\n",
        "        \"band_index\": (step % num_bands) + 1,\n",
        "        \"snr\": snr,\n",
        "        \"ber\": ber_real,\n",
        "        \"detection_prob\": prob_real,\n",
        "        \"is_detected\": is_detected_real,\n",
        "        \"false_positive_rate\": false_positive_rate\n",
        "    }"
      ],
      "metadata": {
        "id": "UT5Ef9p3_bdg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_audio_pfb(audio_data, sr, num_watermarks=NUM_WATERMARKS, alpha=0.5, num_bands=4):\n",
        "    \"\"\"Processes a single audio file using the PFB method incrementally.\"\"\"\n",
        "    original_audio = preprocess_audio(audio_data, sr)\n",
        "    watermarked_audio = original_audio.clone()\n",
        "    results = []\n",
        "\n",
        "    print(f\"Processing audio with PFB (Num Watermarks: {num_watermarks}, Alpha: {alpha}, Bands: {num_bands})\")\n",
        "    initial_snr = calculate_snr(original_audio, original_audio) # Should be inf or high\n",
        "    print(f\"Initial SNR: {initial_snr:.2f} dB\")\n",
        "\n",
        "\n",
        "    for step in range(num_watermarks):\n",
        "        print(f\"--- Embedding Step {step+1} (Band { (step % num_bands) + 1 }) ---\")\n",
        "        # Embed watermark for the current step\n",
        "        watermarked_audio = embed_pfb(watermarked_audio, SAMPLE_RATE, step, alpha, num_bands)\n",
        "\n",
        "        # Calculate metrics *after* this step's watermark is embedded\n",
        "        # The metrics reflect the state *with* watermark 'step' included\n",
        "        metrics = calculate_metrics_pfb(\n",
        "            original=original_audio, # Compare against the original for cumulative SNR/BER\n",
        "            watermarked=watermarked_audio,\n",
        "            step=step, # 0-indexed step for detection logic\n",
        "            num_bands=num_bands\n",
        "        )\n",
        "        results.append(metrics)\n",
        "        print(f\"Step {step+1} Metrics: SNR={metrics['snr']:.2f}, BER={metrics['ber']:.2f}, DetProb={metrics['detection_prob']:.2f}, Detected={metrics['is_detected']}, FPR={metrics['false_positive_rate']:.2f}\")\n",
        "\n",
        "\n",
        "    print(\"-\" * 20)\n",
        "    return pd.DataFrame(results)\n"
      ],
      "metadata": {
        "id": "lKMh5w1J_lSq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Example Usage ---\n",
        "# Load your audio data here (replace with actual loading)\n",
        "# Example: using a dummy sine wave\n",
        "# duration_sec = 5\n",
        "# frequency = 440\n",
        "# t = torch.linspace(0, duration_sec, int(SAMPLE_RATE * duration_sec), dtype=torch.float32)\n",
        "# dummy_audio_data = 0.5 * torch.sin(2 * torch.pi * frequency * t)\n",
        "\n",
        "# Assuming you load audio similar to your original notebook:\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"facebook/voxpopuli\", \"en\", split=\"validation\", streaming=True, trust_remote_code=True)\n",
        "audio_samples = [(ex[\"audio\"][\"array\"], ex[\"audio\"][\"sampling_rate\"]) for ex in dataset.take(1)] # Take one sample\n",
        "if audio_samples:\n",
        "    audio_data, original_sr = audio_samples[0]\n",
        "    pfb_results_df = process_audio_pfb(audio_data, original_sr)\n",
        "    print(\"\\nPFB Results DataFrame:\")\n",
        "    print(pfb_results_df)\n",
        "else:\n",
        "    print(\"Could not load audio data.\")"
      ],
      "metadata": {
        "id": "YlvTbOLVek5p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639,
          "referenced_widgets": [
            "e86a4d9c7acb4a0f8ec85deba988f9c4",
            "681efb7a01f744889afdeb11a3acf08c",
            "a36be79510f5469fa411ca82d09c9480",
            "35f512a1297d4451b03ed91c6f3c0980",
            "03f5c3b7f06443d5beae94faeb243dbe",
            "570a1f1350914957af50e70638e3474d",
            "31dd3cc63a8c495a906b2a8f7a900e47",
            "f63940fce735425a8032c8a5d3b8e557",
            "62dc4ec1238e40eabfb49941b2d870cd",
            "a70b5c7358a74b9d85a4ee630a11b4eb",
            "730179dc42404d0795504d87fd4ec58f",
            "ec88b3ad563e4e48b7629ea8790b5ed1",
            "05969d0b5288420f994c994e3230d869",
            "ec5bcc0c9c1e46de808f14cc0650d161",
            "417228c5333147ef882d71185566ec7b",
            "3d0c2b8145194ac689f9a9e4983332a7",
            "83ec8282c1d54a84b0bfe9ba7edebf46",
            "6c5e4b0886084d6cabc56676c20ccb38",
            "c4c6f9d253c74f09adfb2bea910ce81d",
            "9eb1af0792434fa49019e2b5874a20b3",
            "d7cb57823c954af48d8c4a2354e06ad0",
            "4eb4221a72bc414f994f3cf26b4ff655"
          ]
        },
        "outputId": "5ec12f10-d776-4080-cb88-f08888df175f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e86a4d9c7acb4a0f8ec85deba988f9c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "voxpopuli.py:   0%|          | 0.00/8.84k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec88b3ad563e4e48b7629ea8790b5ed1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing audio with PFB (Num Watermarks: 4, Alpha: 0.5, Bands: 4)\n",
            "Warning: Noise power is near zero. Setting SNR to infinity (e.g., 100 dB).\n",
            "Initial SNR: 100.00 dB\n",
            "--- Embedding Step 1 (Band 1) ---\n",
            "Step 1 Metrics: SNR=54.91, BER=0.62, DetProb=0.00, Detected=False, FPR=0.00\n",
            "--- Embedding Step 2 (Band 2) ---\n",
            "Step 2 Metrics: SNR=54.72, BER=0.81, DetProb=0.03, Detected=False, FPR=0.00\n",
            "--- Embedding Step 3 (Band 3) ---\n",
            "Step 3 Metrics: SNR=54.55, BER=0.44, DetProb=0.04, Detected=False, FPR=0.00\n",
            "--- Embedding Step 4 (Band 4) ---\n",
            "Step 4 Metrics: SNR=51.61, BER=0.44, DetProb=0.00, Detected=False, FPR=0.00\n",
            "--------------------\n",
            "\n",
            "PFB Results DataFrame:\n",
            "  method  step  band_index        snr     ber  detection_prob  is_detected  \\\n",
            "0    PFB     1           1  54.906578  0.6250        0.000758        False   \n",
            "1    PFB     2           2  54.720856  0.8125        0.025644        False   \n",
            "2    PFB     3           3  54.549477  0.4375        0.040262        False   \n",
            "3    PFB     4           4  51.607113  0.4375        0.000815        False   \n",
            "\n",
            "   false_positive_rate  \n",
            "0                  0.0  \n",
            "1                  0.0  \n",
            "2                  0.0  \n",
            "3                  0.0  \n"
          ]
        }
      ]
    }
  ]
}