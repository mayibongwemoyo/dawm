{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mayibongwemoyo/dawm/blob/main/examples/comprehensive_voxpopuli_Incremental_watermarking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4f90bd00-6cca-4b24-a35c-da9f92a4a616",
      "metadata": {
        "id": "4f90bd00-6cca-4b24-a35c-da9f92a4a616"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "import sys\n",
        "!pip install torchaudio soundfile matplotlib scipy datasets pandas seaborn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install audioseal\n"
      ],
      "metadata": {
        "id": "PZO-DgjcF4JZ"
      },
      "id": "PZO-DgjcF4JZ",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENIyvl5XJehd",
        "outputId": "81be43d8-5d1e-48af-8d89-7c839c9ffa49"
      },
      "id": "ENIyvl5XJehd",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/dawm/examples')\n",
        "import noteb00k\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchaudio\n",
        "from audioseal import AudioSeal\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "DvG_OuPVF5OO"
      },
      "id": "DvG_OuPVF5OO",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a subset of VoxPopuli (example: 50 audios)\n",
        "dataset = load_dataset(\"facebook/voxpopuli\", \"en\", split=\"validation\", streaming=True)\n",
        "audios_to_test = []\n",
        "for i, example in enumerate(dataset):\n",
        "    if i >= 50:\n",
        "        break\n",
        "    audio_array = example[\"audio\"][\"array\"]\n",
        "    sr = example[\"audio\"][\"sampling_rate\"]\n",
        "    audios_to_test.append((torch.tensor(audio_array).float(), sr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC6rLomb7hiJ",
        "outputId": "ffcf8d5c-0675-4271-af25-852e669dbf4f"
      },
      "id": "lC6rLomb7hiJ",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_audio(audio, sr):\n",
        "    # Ensure audio is a PyTorch tensor\n",
        "    if isinstance(audio, np.ndarray):\n",
        "        audio = torch.from_numpy(audio).float()\n",
        "\n",
        "    # Convert to 3D: (batch=1, channels=1, time)\n",
        "    if audio.dim() == 1:  # (time) → (1, 1, time)\n",
        "        audio = audio.unsqueeze(0).unsqueeze(0)\n",
        "    elif audio.dim() == 2:  # (channels, time) → (1, channels, time)\n",
        "        audio = audio.unsqueeze(0)\n",
        "    elif audio.dim() == 3:  # Already (batch, channels, time)\n",
        "        pass\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported audio shape: {audio.shape}\")\n",
        "\n",
        "    # Ensure mono audio by averaging channels\n",
        "    if audio.shape[1] > 1:\n",
        "        audio = audio.mean(dim=1, keepdim=True)\n",
        "\n",
        "    # Resample to 16kHz if needed\n",
        "    if sr != 16000:\n",
        "        resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=16000)\n",
        "        audio = resampler(audio)\n",
        "        sr = 16000\n",
        "\n",
        "    # Generate messages (4 real, 4 fake)\n",
        "    real_messages = [torch.randint(0, 2, (1, 16)) for _ in range(4)]\n",
        "    fake_messages = [torch.randint(0, 2, (1, 16)) for _ in range(4)]\n",
        "\n",
        "    # Embed ONLY real watermarks\n",
        "    watermarked_audio = audio.clone()\n",
        "    for i in range(len(real_messages)):\n",
        "        generator = AudioSeal.load_generator(\"audioseal_wm_16bits\")\n",
        "        print(f\"Shape before generator {i+1}: {watermarked_audio.shape}\")\n",
        "        watermarked_audio = generator(\n",
        "            watermarked_audio,\n",
        "            sample_rate=sr,\n",
        "            alpha=0.5/(i+1)\n",
        "        )\n",
        "        print(f\"Shape after generator {i+1}: {watermarked_audio.shape}\")\n",
        "\n",
        "    # Test detection - FIXED LOOP HERE\n",
        "    results = []\n",
        "    for msg_idx, msg in enumerate(real_messages + fake_messages):  # Changed to enumerate\n",
        "        detector = AudioSeal.load_detector(\"audioseal_detector_16bits\")\n",
        "        detector.message = msg\n",
        "        prob, detected_msg = detector.detect_watermark(watermarked_audio, sample_rate=sr)\n",
        "\n",
        "        prob_value = prob if isinstance(prob, float) else prob.item()\n",
        "        ber = (msg != detected_msg.round()).float().mean().item()\n",
        "\n",
        "        results.append({\n",
        "            \"msg_type\": \"real\" if msg_idx < len(real_messages) else \"fake\",  # Use msg_idx\n",
        "            \"ber\": ber,\n",
        "            \"prob\": prob_value\n",
        "        })\n",
        "\n",
        "    # Calculate metrics\n",
        "    noise = watermarked_audio - audio\n",
        "    snr = 10 * torch.log10(audio.pow(2).mean() / noise.pow(2).mean()).item()\n",
        "\n",
        "    # Calculate false positives\n",
        "    null_probs = []\n",
        "    for _ in range(1000):\n",
        "        random_msg = torch.randint(0, 2, (1, 16))\n",
        "        detector = AudioSeal.load_detector(\"audioseal_detector_16bits\")\n",
        "        detector.message = random_msg\n",
        "        prob, _ = detector.detect_watermark(watermarked_audio, sample_rate=sr)\n",
        "        prob_value = prob if isinstance(prob, float) else prob.item()\n",
        "        null_probs.append(prob_value)\n",
        "\n",
        "    false_positive_rate = sum(p >= 0.99 for p in null_probs) / len(null_probs)\n",
        "\n",
        "    return {\n",
        "        \"results\": results,\n",
        "        \"snr\": snr,\n",
        "        \"false_positive_rate\": false_positive_rate\n",
        "    }"
      ],
      "metadata": {
        "id": "oxfpKNlJ7tO9"
      },
      "id": "oxfpKNlJ7tO9",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_results = []\n",
        "for audio, sr in audios_to_test:\n",
        "    metrics = process_audio(audio, sr)\n",
        "    all_results.append(metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfSldmUSir8f",
        "outputId": "f968451f-42b2-4822-9e14-5bf11df6d966"
      },
      "id": "tfSldmUSir8f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape before generator 1: torch.Size([1, 1, 245439])\n",
            "Shape after generator 1: torch.Size([1, 1, 245439])\n",
            "Shape before generator 2: torch.Size([1, 1, 245439])\n",
            "Shape after generator 2: torch.Size([1, 1, 245439])\n",
            "Shape before generator 3: torch.Size([1, 1, 245439])\n",
            "Shape after generator 3: torch.Size([1, 1, 245439])\n",
            "Shape before generator 4: torch.Size([1, 1, 245439])\n",
            "Shape after generator 4: torch.Size([1, 1, 245439])\n",
            "Shape before generator 1: torch.Size([1, 1, 129279])\n",
            "Shape after generator 1: torch.Size([1, 1, 129279])\n",
            "Shape before generator 2: torch.Size([1, 1, 129279])\n",
            "Shape after generator 2: torch.Size([1, 1, 129279])\n",
            "Shape before generator 3: torch.Size([1, 1, 129279])\n",
            "Shape after generator 3: torch.Size([1, 1, 129279])\n",
            "Shape before generator 4: torch.Size([1, 1, 129279])\n",
            "Shape after generator 4: torch.Size([1, 1, 129279])\n",
            "Shape before generator 1: torch.Size([1, 1, 189760])\n",
            "Shape after generator 1: torch.Size([1, 1, 189760])\n",
            "Shape before generator 2: torch.Size([1, 1, 189760])\n",
            "Shape after generator 2: torch.Size([1, 1, 189760])\n",
            "Shape before generator 3: torch.Size([1, 1, 189760])\n",
            "Shape after generator 3: torch.Size([1, 1, 189760])\n",
            "Shape before generator 4: torch.Size([1, 1, 189760])\n",
            "Shape after generator 4: torch.Size([1, 1, 189760])\n",
            "Shape before generator 1: torch.Size([1, 1, 145600])\n",
            "Shape after generator 1: torch.Size([1, 1, 145600])\n",
            "Shape before generator 2: torch.Size([1, 1, 145600])\n",
            "Shape after generator 2: torch.Size([1, 1, 145600])\n",
            "Shape before generator 3: torch.Size([1, 1, 145600])\n",
            "Shape after generator 3: torch.Size([1, 1, 145600])\n",
            "Shape before generator 4: torch.Size([1, 1, 145600])\n",
            "Shape after generator 4: torch.Size([1, 1, 145600])\n",
            "Shape before generator 1: torch.Size([1, 1, 133110])\n",
            "Shape after generator 1: torch.Size([1, 1, 133110])\n",
            "Shape before generator 2: torch.Size([1, 1, 133110])\n",
            "Shape after generator 2: torch.Size([1, 1, 133110])\n",
            "Shape before generator 3: torch.Size([1, 1, 133110])\n",
            "Shape after generator 3: torch.Size([1, 1, 133110])\n",
            "Shape before generator 4: torch.Size([1, 1, 133110])\n",
            "Shape after generator 4: torch.Size([1, 1, 133110])\n",
            "Shape before generator 1: torch.Size([1, 1, 55680])\n",
            "Shape after generator 1: torch.Size([1, 1, 55680])\n",
            "Shape before generator 2: torch.Size([1, 1, 55680])\n",
            "Shape after generator 2: torch.Size([1, 1, 55680])\n",
            "Shape before generator 3: torch.Size([1, 1, 55680])\n",
            "Shape after generator 3: torch.Size([1, 1, 55680])\n",
            "Shape before generator 4: torch.Size([1, 1, 55680])\n",
            "Shape after generator 4: torch.Size([1, 1, 55680])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine results\n",
        "results_df = pd.DataFrame([item for res in all_results for item in res[\"results\"]])\n",
        "\n",
        "# Calculate statistics\n",
        "print(\"Average SNR:\", np.mean([res[\"snr\"] for res in all_results]))\n",
        "print(\"False Positive Rate:\", np.mean([res[\"false_positive_rate\"] for res in all_results]))\n",
        "print(\"\\nDetection Performance:\")\n",
        "print(results_df.groupby(\"msg_type\").mean())"
      ],
      "metadata": {
        "id": "LN3oXiV2depl"
      },
      "id": "LN3oXiV2depl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# all_results = []\n",
        "# for audio, sr in audios_to_test:\n",
        "#     # Ensure audio is tensor and enforce shape\n",
        "#     if isinstance(audio, np.ndarray):\n",
        "#         audio = torch.from_numpy(audio).float()\n",
        "#     audio = audio.unsqueeze(0).unsqueeze(0) if audio.dim() == 1 else audio\n",
        "#     print(f\"Processing audio with shape: {audio.shape}\")  # Debug line\n",
        "\n",
        "#     metrics = process_audio(audio, sr)\n",
        "#     all_results.append(metrics)"
      ],
      "metadata": {
        "id": "rFubd0t375Wg"
      },
      "id": "rFubd0t375Wg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine SNR data\n",
        "snr_df = pd.DataFrame([r[\"snrs\"] for r in all_results], columns=[f\"WM_{i+1}\" for i in range(4)])\n",
        "snr_summary = snr_df.mean().reset_index(name=\"SNR (dB)\")\n",
        "\n",
        "# Combine BER and detection probability\n",
        "results_df = pd.concat([r[\"results\"] for r in all_results])\n",
        "ber_summary = results_df.groupby([\"msg_type\", \"watermark_count\"]).ber.mean().reset_index()\n",
        "prob_summary = results_df.groupby([\"msg_type\", \"watermark_count\"]).prob.mean().reset_index()\n",
        "\n",
        "# False positive rates\n",
        "fp_rates = [r[\"false_positive_rate\"] for r in all_results]"
      ],
      "metadata": {
        "id": "hl8_oyeu8Mcn"
      },
      "id": "hl8_oyeu8Mcn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "sns.lineplot(data=snr_summary, x=\"index\", y=\"SNR (dB)\", marker=\"o\")\n",
        "plt.title(\"Average SNR vs. Number of Watermarks\")\n",
        "plt.xlabel(\"Watermark Count\")\n",
        "plt.xticks(ticks=range(4), labels=[\"1\", \"2\", \"3\", \"4\"])\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-bT9hKLV8PXG"
      },
      "id": "-bT9hKLV8PXG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "sns.lineplot(data=ber_summary, x=\"watermark_count\", y=\"ber\", hue=\"msg_type\", marker=\"o\")\n",
        "plt.title(\"Average BER vs. Watermark Count\")\n",
        "plt.xlabel(\"Watermark Count\")\n",
        "plt.ylabel(\"Bit Error Rate (BER)\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YaEMGH2w8RBa"
      },
      "id": "YaEMGH2w8RBa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(fp_rates, bins=20, kde=True)\n",
        "plt.title(\"Distribution of False Positive Rates Across Audios\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.xlim(0, 1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hI5luf5d8Uee"
      },
      "id": "hI5luf5d8Uee",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "sns.kdeplot(real_probs, label=\"Real Watermarks\", fill=True)\n",
        "sns.kdeplot(fake_probs, label=\"Fake Watermarks\", fill=True)\n",
        "plt.axvline(0.5, color=\"red\", linestyle=\"--\", label=\"Random Guess Threshold\")\n",
        "plt.title(\"Detection Probability Distribution (Real vs. Fake)\")\n",
        "plt.xlabel(\"Probability\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TgrPjpE7-WDO"
      },
      "id": "TgrPjpE7-WDO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "741903b8-d97c-472d-a821-f61cdbe8481f",
      "metadata": {
        "id": "741903b8-d97c-472d-a821-f61cdbe8481f"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams[\"figure.figsize\"] = (20,3)\n",
        "\n",
        "from noteb00k import play_audio, plot_waveform_and_specgram\n",
        "\n",
        "plot_waveform_and_specgram(audio, sr, title=\"Original audio\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9af1710d-634d-4f31-8509-a478b5cdb4b2",
      "metadata": {
        "id": "9af1710d-634d-4f31-8509-a478b5cdb4b2"
      },
      "outputs": [],
      "source": [
        "play_audio(audio, sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c5423cf-1c9f-42b4-b77d-b7ec21085f86",
      "metadata": {
        "id": "5c5423cf-1c9f-42b4-b77d-b7ec21085f86"
      },
      "outputs": [],
      "source": [
        "# Initialise Audioseal models\n",
        "from audioseal import AudioSeal\n",
        "\n",
        "# Load models\n",
        "generator = AudioSeal.load_generator(\"audioseal_wm_16bits\")\n",
        "detector = AudioSeal.load_detector((\"audioseal_detector_16bits\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c74696ef-4a08-4859-86bb-f6505f19daba",
      "metadata": {
        "id": "c74696ef-4a08-4859-86bb-f6505f19daba"
      },
      "outputs": [],
      "source": [
        "# Generate 3 real messages and 1 fake\n",
        "real_messages = [torch.randint(0, 2, (1, 16)) for _ in range(3)]\n",
        "fake_messages = [torch.randint(0, 2, (1, 16)) for _ in range(3)]\n",
        "\n",
        "# Combine messages\n",
        "all_messages = real_messages + fake_messages\n",
        "\n",
        "for i, msg in enumerate(all_messages):\n",
        "    print(f\"Message {i+1}: {msg.numpy().flatten()}\")  # Verify uniqueness\n",
        "\n",
        "audios = audio.unsqueeze(0)  # Add batch dimension (if missing)\n",
        "# audio = audio.unsqueeze(1)  # Add channel dimension (if mono)\n",
        "\n",
        "\n",
        "watermarked_audio = audios.clone()  # Start with original audio\n",
        "\n",
        "# Embed watermarks sequentially\n",
        "for idx, msg in enumerate(real_messages):\n",
        "    # Generate watermark for current message\n",
        "    watermark = generator.get_watermark(watermarked_audio, sample_rate=sr)\n",
        "\n",
        "    # Apply watermark with scaled strength\n",
        "    # watermarked_audio = audios + watermark\n",
        "    watermarked_audio = generator(watermarked_audio, sample_rate=sr, alpha=0.5/(idx+1))\n",
        "\n",
        "\n",
        "    # Calculate metrics after EACH embedding\n",
        "    noise = watermarked_audio - audios\n",
        "    snr = 10 * torch.log10(audios.pow(2).mean() / noise.pow(2).mean())\n",
        "\n",
        "    print(f\"\\nAfter Watermark {idx+1}:\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"  SNR: {snr:.2f} dB\")\n",
        "\n",
        "print(\"\\nFinal Detection Results:\")\n",
        "# Detect ALL previous watermarks\n",
        "for detect_idx, msg in enumerate(all_messages):\n",
        "    # Create NEW detector for each test\n",
        "    temp_detector = AudioSeal.load_detector(\"audioseal_detector_16bits\")\n",
        "    temp_detector.message = msg\n",
        "\n",
        "    prob, detected_msg = temp_detector.detect_watermark(watermarked_audio,sample_rate=sr, message_threshold=0.5)\n",
        "    ber = (msg != detected_msg.round()).float().mean()\n",
        "\n",
        "    status = \"REAL\" if detect_idx < len(real_messages) else \"FAKE\"\n",
        "    print(f\"  Watermark {detect_idx+1}: BER={ber:.2f}, Prob={prob:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate empirical p-value for fake detection\n",
        "null_probs = []\n",
        "for _ in range(1000):  # Increase for tighter confidence intervals\n",
        "    # 1. Generate random message\n",
        "    random_msg = torch.randint(0, 2, (1, 16))\n",
        "\n",
        "    # 2. Fresh detector instance\n",
        "    temp_detector = AudioSeal.load_detector(\"audioseal_detector_16bits\")\n",
        "    temp_detector.message = random_msg\n",
        "\n",
        "    # 3. Proper output handling\n",
        "    detection_result = temp_detector.detect_watermark(watermarked_audio, sample_rate=sr)\n",
        "    if isinstance(detection_result, tuple):\n",
        "        prob = detection_result[0]  # Get probability from tuple\n",
        "    else:\n",
        "        prob = detection_result  # Single value\n",
        "\n",
        "    null_probs.append(float(prob))  # Explicit conversion\n",
        "\n",
        "# Calculate p-value with continuity correction\n",
        "extreme_count = sum(p >= 0.99 for p in null_probs)  # Count near-perfect detections\n",
        "p_value = (extreme_count + 1) / (len(null_probs) + 1)\n",
        "print(f\"False positive rate: {100*extreme_count/len(null_probs):.2f}%\")\n",
        "print(f\"p-value: {p_value:.6f} (n={len(null_probs)})\")"
      ],
      "metadata": {
        "id": "LlqpQn4amVMY"
      },
      "id": "LlqpQn4amVMY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07c43518-ed6b-4674-a25d-543613c768b3",
      "metadata": {
        "id": "07c43518-ed6b-4674-a25d-543613c768b3"
      },
      "outputs": [],
      "source": [
        "# Calculate SNR\n",
        "noise = watermarked_audio - audios\n",
        "snr = 10 * torch.log10(audios.pow(2).mean() / noise.pow(2).mean())\n",
        "print(f\"Final SNR: {snr:.2f} dB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5994b38f-5141-431a-940f-881eb47c7526",
      "metadata": {
        "id": "5994b38f-5141-431a-940f-881eb47c7526"
      },
      "outputs": [],
      "source": [
        "plot_waveform_and_specgram(watermarked_audio.squeeze(), sr, title=\"Multi-Watermarked Audio\")\n",
        "play_audio(watermarked_audio, sr)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}