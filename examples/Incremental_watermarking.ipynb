{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f90bd00-6cca-4b24-a35c-da9f92a4a616",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# For the demonstration, we need torchaudio and matplotlib to process example audios and visualize the spectrogram\n",
    "import sys\n",
    "!{sys.executable} -m pip install torchaudio soundfile matplotlib scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75e5326-38dd-472f-9274-5b5150d6f02a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.path.exists(r\"C:\\Users\\x\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\audioseal\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6f8d65-b05b-42b7-8335-cf4de15aabef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import urllib\n",
    "\n",
    "def download_sample_audio():\n",
    "    url = \"https://keithito.com/LJ-Speech-Dataset/LJ025-0076.wav\"\n",
    "    with open(\"test.wav\", \"wb\") as f:\n",
    "        resp = urllib.request.urlopen(url)\n",
    "        f.write(resp.read())\n",
    "    \n",
    "    wav, sample_rate = torchaudio.load(\"test.wav\")\n",
    "    return wav, sample_rate\n",
    "\n",
    "audio, sr = download_sample_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741903b8-d97c-472d-a821-f61cdbe8481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,3)\n",
    "\n",
    "from notebook import play_audio, plot_waveform_and_specgram\n",
    "\n",
    "plot_waveform_and_specgram(audio, sr, title=\"Original audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af1710d-634d-4f31-8509-a478b5cdb4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_audio(audio, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5423cf-1c9f-42b4-b77d-b7ec21085f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise Audioseal models\n",
    "from audioseal import AudioSeal\n",
    "\n",
    "# Load models\n",
    "generator = AudioSeal.load_generator(\"audioseal_wm_16bits\")\n",
    "detector = AudioSeal.load_detector((\"audioseal_detector_16bits\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74696ef-4a08-4859-86bb-f6505f19daba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 4 UNIQUE messages (16-bit)\n",
    "messages = [torch.randint(0, 2, (1, 16)) for _ in range(4)]\n",
    "\n",
    "for i, msg in enumerate(messages):\n",
    "    print(f\"Message {i+1}: {msg.numpy().flatten()}\")  # Verify uniqueness\n",
    "\n",
    "# Initialize variables\n",
    "sr = 16000\n",
    "original_audio = torch.randn(1, 1, sr)  # Test audio (1s @16kHz)\n",
    "watermarked_audio = original_audio.clone()\n",
    "alpha = 0.25  # Reduced strength for multiple embeddings  \n",
    "\n",
    "# # If loading real audio (e.g., from torchaudio):\n",
    "# audio, sr = torchaudio.load(\"test.wav\")\n",
    "# audio = audio.unsqueeze(0)  # Add batch dimension (if missing)\n",
    "# audio = audio.unsqueeze(1)  # Add channel dimension (if mono)\n",
    "\n",
    "# Embed watermarks sequentially\n",
    "for idx, msg in enumerate(messages):\n",
    "    # Generate watermark for current message\n",
    "    watermark = generator.get_watermark(\n",
    "        watermarked_audio, \n",
    "        sample_rate=sr,\n",
    "        message=msg\n",
    "    )\n",
    "\n",
    "    # Apply watermark with reduced strength\n",
    "    watermarked_audio = watermarked_audio + alpha * watermark\n",
    "    \n",
    "    # Calculate metrics after EACH embedding\n",
    "    noise = watermarked_audio - original_audio\n",
    "    snr = 10 * torch.log10(original_audio.pow(2).mean() / noise.pow(2).mean())\n",
    "    \n",
    "    print(f\"\\nAfter Watermark {idx+1}:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"  SNR: {snr:.2f} dB\")\n",
    "\n",
    "    # Detect ALL previous watermarks\n",
    "    for detect_idx in range(idx+1):\n",
    "        detector.message = messages[detect_idx]  # Critical: Reset detector state\n",
    "        prob, detected_msg = detector.detect_watermark(watermarked_audio,sample_rate=sr, message_threshold=0.5)\n",
    "        ber = (messages[detect_idx] != detected_msg.round()).float().mean()\n",
    "        print(f\"  Watermark {detect_idx+1}: BER={ber:.2f}, Prob={prob:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c43518-ed6b-4674-a25d-543613c768b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SNR\n",
    "noise = watermarked_audio - original_audio\n",
    "snr = 10 * torch.log10(original_audio.pow(2).mean() / noise.pow(2).mean())\n",
    "print(f\"Final SNR: {snr:.2f} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5994b38f-5141-431a-940f-881eb47c7526",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_waveform_and_specgram(watermarked_audio.squeeze(), sr, title=\"Multi-Watermarked Audio\")\n",
    "play_audio(watermarked_audio, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3215c576-2d48-4cb6-a557-fa6aa56befaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Detect watermarks\n",
    "# def detect_watermarks(watermarked_audio, messages):\n",
    "#     results = []\n",
    "#     for msg in messages:\n",
    "#         detector.message = msg  # Force detector to look for this message\n",
    "#         prob, decoded_msg = detector.detect_watermark(watermarked_audio, sample_rate=sr)\n",
    "#         ber = (msg != decoded_msg.round()).float().mean()\n",
    "#         results.append((prob, ber))\n",
    "#     return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2425b7eb-42cf-45d8-93d6-c53e175328f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb73d335-95f3-48b5-98cc-0d5f1dd580c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply attacks\n",
    "from attacks1 import AudioEffects1 as attacks1\n",
    "# Apply MP3 compression\n",
    "attacked_audio = attacks.mp3_compression(watermarked_audio, bitrate=64)\n",
    "\n",
    "# Detect after attack\n",
    "attacked_results = detect_watermarks(attacked_audio, messages)\n",
    "                                    \n",
    "print(\"Compressed audio shape:\", compressed_audio.shape)\n",
    "                                     \n",
    "print(\"\\n--- After MP3 Compression (64 kbps) ---\")\n",
    "for i, (prob, ber) in enumerate(attacked_results):\n",
    "    print(f\"Watermark {i+1}: Detection Prob = {prob:.2f}, BER = {ber:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4109a3f-fd99-4267-a8a3-a9340109cee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_waveform_and_specgram(watermarked_audio.squeeze(), sr, title=\"Multi-Watermarked Audio\")\n",
    "play_audio(watermarked_audio, sr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
